{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sequential API\n",
        "\n",
        "Sequential API реализуется посредством класса `nn.Sequential` и подходит для простых линейных архитектур. В конструкторе слоям присваиваются имена (`0, 1, ...`). Всякий компонент сети, который можно состыковать с другими компонентами, будь это слой или целая сеть, называется модулем.\n",
        "\n",
        "> Для явного именования модулей в конструкторе `nn.Sequential` можно использовать `OrderedDict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=20, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=20, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch import nn \n",
        "\n",
        "flatten = nn.Flatten()  # создается слой для выравнивания тензора\n",
        "\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,    # добавление ранее созданного модуля\n",
        "    nn.Linear(in_features=28*28, out_features=20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10),\n",
        ")\n",
        "\n",
        "# добавление модуля после того, как последовательность создана\n",
        "seq_modules.add_module(name=\"softmax\", module=nn.Softmax())\n",
        "\n",
        "seq_modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "При добавлении модуля вне конструктора класса при помощи метода `add_module()` необходимо задавать значение `name`. Если при этом заданное значение уже существует в модели, то этот модуль будет заменен добавляемым модулем.\n",
        "\n",
        "Доступ к модулю можно получить по индексу:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=20, bias=True)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_modules[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Доступ к модулю можно получить также и по имени слоя, если обратиться к полю `_modules`, в котором содержатся слои в виде словаря, ключами которого являются имена:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Softmax(dim=None)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_modules._modules[\"softmax\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Subclassing API\n",
        "\n",
        "Для полного контроля над архитектурой необходимо создать класс, наследующий класс `Module` из модуля `nn`. Модули определяются в конструкторе, а в методе `forward` задается специфика прохождения данных через сеть. Напрямую этот метод вызывать не сто́ит. Полный API [здесь](https://pytorch.org/docs/stable/nn.html).\n",
        "\n",
        "Так как сеть, построенная при помощи `nn.Sequential()` является полноценным модулем, то ничего не мешает создать такой (или использовать готовый) модуль в конструкторе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7js4D6secxc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch import nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(in_features=28*28,\n",
        "                      out_features=512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "        self.add_module(\"softmax\", nn.Softmax())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "    \n",
        "model = NeuralNetwork()\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Заметим, что имена модулям присваиваются в соответствии с именами полей. При желании можно определить непосредственно имя модуля, если добавлять его при помощи метода `add_module()`.\n",
        "\n",
        "Доступ к модулям может быть произведен как через непосредственное обращение к полю, так и через имя:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Flatten(start_dim=1, end_dim=-1), Softmax(dim=None))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.flatten, model._modules[\"softmax\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnH2g2Becxc7"
      },
      "source": [
        "Результат возвращаемый нейронным слоем без функции активации принято называть `logits` (не путать с функцией logit!), и содержит произвольные значения. В классе `NeuralNetwork` мы добавилди модуль `softmax` в конструкторе, но не задействован в методе `forward()`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A8yX2BWcxc7"
      },
      "source": [
        "Для ускорения операций мы можем задать специфику при создании объекта модели. Для начала выясним, что есть в доступе:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaFLknC6cxc8",
        "outputId": "d7c6d7aa-8c68-4e71-e804-b376d46f2168"
      },
      "outputs": [],
      "source": [
        "device = (\n",
        "         \"cuda\" if torch.cuda.is_available()\n",
        "    # else \"mps\"  if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVmaS_05cxc9",
        "outputId": "fa4402d9-9ad4-44bd-92ae-283a631e8148"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dICOtjw0cxc_"
      },
      "source": [
        "Для прогноза можно вызывать модель, передав ей данные. Модель возвратит двумерный тензор, в котором первая размерность (`dim=0`) соответствует образцам, а вторая размерность (`dim=1`) соответствует выходным значениям сети.\n",
        "\n",
        "Мы можем применить отдельно слой `Softmax`, чтобы получить распределение вероятностей (в конструкторе указывается измерение, вдоль которого применяется softmax):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3i5jH9ccxdA",
        "outputId": "8a36d0ec-61ed-4da5-d5a9-482ff8e51948"
      },
      "outputs": [],
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "print(pred_probab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {int(y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybh7TZaWcxdB"
      },
      "source": [
        "В выражении `nn.Softmax(dim=1)(logits)` создается объект слоя `Softmax` и тут же вызывается с входным значением `logits`. Таким образом мы вольны создавать отдельные слои, или последовательность слоев, не определяя для этого пользовательский класс. Для этого используется упорядоченный контейнер для модулей `Sequential`. Данные пройдут через все модули в том же порядке, как и определены."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQg3qis0cxdC",
        "outputId": "64138c0f-762b-4476-a544-dbdb9ab5490c"
      },
      "outputs": [],
      "source": [
        "flatten = nn.Flatten()\n",
        "\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,    # добавление ранее созданного модуля\n",
        "    nn.Linear(in_features=28*28, out_features=20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10),\n",
        ")\n",
        "# добавление модуля после того, как последовательность создана\n",
        "seq_modules.add_module(name=\"4\", module=nn.Softmax())\n",
        "seq_modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZHhAmxFcxdF"
      },
      "source": [
        "# Training\n",
        "\n",
        "Определим [оптимизатор](https://pytorch.org/docs/stable/optim.html) и [функцию потерь](https://pytorch.org/docs/stable/nn.html#loss-functions). Заметим, что первым аргументом в конструктор оптимизатора передается генератор, содержащий параметры модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov7RaLS1cxdF"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxStXyDicxdH"
      },
      "source": [
        "Определим функцию для одной эпохи. Модель производит прогнозы для тренировочного набора, скармливая данные партиями, и производит обратное распространение ошибки для коррекции параметров. Оптимизация производится в три этапа:\n",
        "\n",
        "- Вызывается метод `zero_grad()` оптимизатора, для того, чтобы сбросить градиенты параметров модели, так как по умолчанию, градиенты будут складываться.\n",
        "- Вызывается метод `backward()` у целевой функции, чтобы произвести обратное распространение. Вычисляемые при этом градиенты сохраняются в тензорах, в которых хранятся параметры.\n",
        "- После того, как градиенты получены, вызывается метод `step()` оптимизатора, чтобы произвести коррекцию параметров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brj_NjpUcxdH"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh1AG67UcxdI"
      },
      "source": [
        "Для того, чтобы отслеживать работу сети на тестовых данных, создадим тестовую функцию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHWMFkcvcxdJ"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tweiQSgcxdK"
      },
      "source": [
        "Запустим обучение на 5 эпохах. Будем выводить accuracy и loss на каждой эпохе:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQHHd77FcxdL",
        "outputId": "b412d947-a274-4bea-9974-8008f0e0f767"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIX1648qcxdM"
      },
      "source": [
        "# Saving and Loading Models\n",
        "\n",
        "Функция `save()` позволяет сохранить модель путем сериализации внутреннего словаря состояний, содержащего параметры модели:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD_apoLZcxdN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVqSvL8HcxdO"
      },
      "source": [
        "Для загрузки необходимо создать модель соответствующей структуры, и загрузить в него словарь состояний. Для загрузки словаря используется функция `load()`, а для того, чтобы установить эти данные в модели используется методы `load_state_dict()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKYqIdH1cxdP",
        "outputId": "2d122baf-a45b-4810-8cf7-90d03f24214a"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq1jR4ypcxdQ"
      },
      "source": [
        "Более подробно о сохранении и загрузке моделей [здесь](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POzBgvyOcxdR"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Для перевода модели в режим инференса, необходимо вызвать метод `eval()`. Это оптимизирует вычисление: отключаются dropout и batch normalization, не вычисляются градиенты и тд."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGRTRajwcxdR",
        "outputId": "003fc6f0-685c-435a-bcdc-bd7ae42eeb6d"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "# model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "zoo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
